#!/usr/bin/env python2
# vim:fileencoding=utf-8

from __future__ import (
    unicode_literals,
    division,
    absolute_import,
    print_function
)
import json
import datetime
from dateutil import relativedelta
from dateutil.tz import tzutc

from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import BeautifulSoup as Soup


class TheEconomistRecipe(BasicNewsRecipe):
    title = "The Economist"
    oldest_article = 13
    max_articles_per_feed = 200
    auto_cleanup = True
    use_embedded_content = False
    publication_type = "magazine"
    needs_subscription = True
    handle_gzip = True
    timefmt = ""

    def x_fetch_url(self, url):
        br = self.get_browser()
        resp = br.open(url)
        data = resp.read()
        return data

    def x_fetch_articles(self):
        base_url = "http://www.economist.com"
        start_url = "/".join([base_url, "printedition"])
        content = self.x_fetch_url(start_url)
        soup = Soup(content)
        divmain = (
            soup.find(
                "div",
                attrs={
                    "class": (
                        "div.main-content__main-column print-edition__content"
                    )
                }
            )
        )
        if divmain is None:
            return None
        ul = (
            divmain.find(
                "ul",
                attrs={
                    "class": "list"
                }
            )
        )
        if ul is None:
            return None
        items = (
            ul.findAll(
                "li",
                attrs={
                    "class": "list__item"
                },
                recursive=False
            )
        )
        if (items is None) or (len(items) == 0):
            return None
        feeds = []
        for item in items:
            divtitle = (
                item.find(
                    "div",
                    atts={
                        "class": "list__title"
                    }
                )
            )
            if divtitle is None:
                continue
            feed_title = divtitle.string.strip()
            links = (
                item.findAll(
                    "a",
                    attrs={
                        "class": "link-button list__link"
                    },
                    recursive=False
                )
            )
            if (links is None) or (len(links) == 0):
                continue
            for link in links:
                if not link.has_key("href"):
                    continue
                url = "/".join([base_url, link["href"]])
                spanflytitle = (
                    link.find(
                        "span",
                        attrs={
                            "class": "print-edition__link-flytitle"
                        }
                    )
                )
                spantitle = (
                    link.find(
                        "span",
                        attrs={
                            "class": "print-edition__link-title"
                        }
                    )
                )
                if (spanflytitle is None):
                    title = link.string.strip()
                else:
                    title = spanflytitle.string.strip()
                if (spantitle is None):
                    subtitle = ""
                else:
                    subtitle = spantitle.string.strip()
                article = {
                    "title": title,
                    "url": url,
                    "date": 1,
                    "description": subtitle,
                    "content": ""
                }
                articles.append(article)
            feeds.append((
                feed_title,
                articles
            ))
        return feeds

    def parse_index(self):
        res = self.x_fetch_articles()
        if res is None:
            return []
        return res
