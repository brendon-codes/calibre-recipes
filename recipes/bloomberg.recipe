#!/usr/bin/env python2
# vim:fileencoding=utf-8

from __future__ import (
    unicode_literals,
    division,
    absolute_import,
    print_function
)
import dateutil
import datetime
from pprint import pprint
from calibre.web.feeds.news import BasicNewsRecipe


class BloombergRecipe(BasicNewsRecipe):
    title = "Bloomberg"
    __author__ = "Brendon Crawford"
    oldest_article = 2
    max_articles_per_feed = 100
    auto_cleanup = True
    use_embedded_content = False
    publication_type = "newspaper"
    timefmt = ""
    delay = 1
    feeds = [
        (
            "Markets",
            "https://www.bloomberg.com/markets"
        )
        #(
        #    "Technology",
        #    "https://www.bloomberg.com/technology"
        #)
    ]

    def parse_index(self):
        root_url = "https://www.bloomberg.com"
        outfeeds = []
        all_urls = set()
        for feed_title, feed_url in self.feeds:
            soup = (
                self.index_to_soup(feed_url)
            )
            soup_arts = (
                soup.findAll(
                    "div",
                    attrs={
                        "class": "tech-hero__story"
                    }
                ) +
                soup.findAll(
                    "article"
                )
            )
            articles = []
            for tag_article in soup_arts:
                tag_anchors = (
                    tag_article.findAll(
                        "a",
                        attrs={
                            "data-resource-type": "article"
                        },
                        href=True
                    ) +
                    tag_article.findAll(
                        "a",
                        attrs={
                            "class": "story-list-article__link"
                        },
                        href=True
                    ) +
                    tag_article.findAll(
                        "a",
                        attrs={
                            "class": "tech-hero__headline"
                        },
                        href=True
                    )
                )
                tag_anchor = None
                title = ""
                for fanchor in tag_anchors:
                    ftitle = (
                        self.tag_to_string(
                            fanchor,
                            use_alt=False,
                            normalize_whitespace=True
                        ).strip()
                    )
                    if ftitle != "":
                        tag_anchor = fanchor
                        title = ftitle
                        break
                if tag_anchor is None:
                    #print("No tag_anchor")
                    continue
                if title == "":
                    #print("Title empty")
                    continue
                href = tag_anchor.get("href")
                if href is None:
                    #print("No href")
                    continue
                url = (
                    href if
                    (
                        href.startswith("https://") or
                        href.startswith("http://")
                    ) else
                    "".join([root_url, href])
                )
                ## Dont add twice
                if url in all_urls:
                    continue
                all_urls.add(url)
                tag_time = (
                    tag_article.find("time")
                )
                if (
                        (tag_time is None) or
                        (tag_time.get("datetime") is None)
                ):
                    date = (
                        datetime
                        .datetime
                        .now(tz=dateutil.tz.tzutc())
                        .replace(
                            hour=0,
                            minute=0,
                            second=0,
                            microsecond=0
                        )
                        .isoformat()
                    )
                else:
                    date = tag_time.get("datetime")
                article = {
                    "title": title,
                    "url": url,
                    "date": date,
                    "description": "",
                    "content": ""
                }
                articles.append(article)
            if len(articles) > 0:
                articles.sort(key=(lambda x: x["date"]), reverse=True)
                outfeeds.append((
                    feed_title,
                    articles
                ))
        #pprint(outfeeds)
        return outfeeds
